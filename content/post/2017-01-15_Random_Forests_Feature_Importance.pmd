---
title: Random Forests using Python for the new year (part 2 - feature importance)
author: elikesprogramming
date: '2017-01-15'
categories:
  - Python
tags:
  - Random Forest
---

In the previous post I ended up with a naive model and explored the performance
metrics available in `scikit-learn`. Now let's move on to exploring how to
assess feature importance.

But first let me fit again the naive model to work with.

```python, echo=False, results='hidden'
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics

from mlxtend.plotting import plot_confusion_matrix
import matplotlib.pyplot as plt
%matplotlib inline
import joypy
import seaborn as sns

import eli5
from eli5.sklearn import PermutationImportance
from mlxtend.evaluate import feature_importance_permutation

from scikitplot.metrics import plot_roc
from scikitplot.metrics import plot_precision_recall

from pytictoc import TicToc

from IPython.display import display_markdown
```

```python, results="raw"
deaths_2016 = pd.read_csv(
    "../../Python/deaths_eevv/data_src/Nofetal_2016.txt",
    sep="\t", encoding="WINDOWS-1252"
)

deaths_2016["MUNI"] = deaths_2016["COD_DPTO"]*1000 + deaths_2016["COD_MUNIC"]
deaths_2016 = deaths_2016.loc[deaths_2016["PMAN_MUER"] != 3]
deaths_2016 = deaths_2016[[
    "PMAN_MUER", "MES", "HORA", "MINUTOS", "SEXO", "EST_CIVIL", "GRU_ED2",
    "NIVEL_EDU", "IDPERTET", "SEG_SOCIAL", "MUNI", "A_DEFUN"
]]
deaths_2016 = deaths_2016.dropna()

X_all = deaths_2016.drop("PMAN_MUER", "columns")
y_all = deaths_2016.loc[:, "PMAN_MUER"]
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(
    X_all, y_all, test_size=0.3, random_state=0
)
from sklearn.ensemble import RandomForestClassifier
rforestclf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)
with TicToc(): # TicToc just to time it
    rforestclf.fit(X_train, y_train)
with TicToc(): # TicToc just to time it
    y_pred = rforestclf.predict(X_test)
with TicToc(): # TicToc just to time it
    y_prob = rforestclf.predict_proba(X_test)
```

# Feature importance

If you look at how to get feature importance from a Random Forest Classifier
using scikit learn, the simplest way you find is probably this (and probably
the first one you find):

```python
list(zip(X_train, rforestclf.feature_importances_))
```
Ok, that works. But ...

- it is ugly
- not sorted (although you can fix that with one line)
- does not show how feature importance varies in the forest

So let's try a simple plot using `matplotlib`, adapting [Chris Albon's code
here](https://chrisalbon.com/machine_learning/trees_and_forests/feature_importance/)

```python
import numpy as np
# need to sort the features by importance and get the names of the features
indices = np.argsort(rforestclf.feature_importances_)[::1]
names = [X_train.columns[i] for i in indices]
import matplotlib.pyplot as plt
plt.figure()
plt.barh(range(X_train.shape[1]), rforestclf.feature_importances_[indices])
plt.yticks(range(X_train.shape[1]), names)
plt.show()
```

Ok, that's better. I just keep missing taking a look at the variability in the
forest. `scikit-learn` has [this example](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html),
where they plot feature importance in a bar plot and add inter-tree variability
as error bars/lines. So let's take that as an inspiration and see what I come
up with. Basically I do not like these bar plots topped with error lines, so
I will try something different.

First, a joy plot

```python
indices = np.argsort(rforestclf.feature_importances_)[::-1]
names = [X_train.columns[i] for i in indices]

import joypy
importance_variability = [tree.feature_importances_ for tree in rforestclf.estimators_]
importance_variability = pd.DataFrame(np.stack(importance_variability))
importance_variability = importance_variability[indices]
importance_variability.columns = names
%matplotlib inline
fig, axes = joypy.joyplot(importance_variability)
```
Ok, now you have a sense of feature importance variability in the forest.
But it seems a lot for the most important variables (which is expected, see
Robin Genuer, Jean-Michel Poggi, Christine Tuleau-Malot. Variable selection
using Random Forests. Pattern Recognition Letters, Elsevier, 2010, 31 (14),
pp.2225-2236. ffhal-00755489f). However, there might also be some over-smoothing
in this kernel density estimate. So let's see also a box plot and perhaps a
violin plot.

```python
import seaborn as sns
importance_variability = importance_variability.melt(var_name='feature',
                                                     value_name='importance')
ax = sns.violinplot(x="importance", y="feature", data=importance_variability,
                    scale="width")
```
Yeah, I think this more accurately reflects what is going on.

```python
row_p = pd.crosstab(y_test, X_test["SEXO"], margins=True, normalize="index")
col_p = pd.crosstab(y_test, X_test["SEXO"], margins=True, normalize="columns")
men_violent_rowp = "{0:.1%}".format(row_p[1][2])
wom_violent_rowp = "{0:.1%}".format(row_p[2][2])
men_violent_colp = "{0:.1%}".format(col_p[1][2])
wom_violent_colp = "{0:.1%}".format(col_p[2][2])
```
Yet, there is something odd with these feature importances. It does not seem
correct that sex has such a low importance in predicting whether it was a
volent death. Indeed, if you look at the raw numbers, being men or women seems
pretty important. Although overall men die slightly more than women, they are
certainly over-represented in the violent deaths. Among all violent deaths, men
account for <%=men_violent_rowp%> and women only <%=wom_violent_rowp%>.
Similarly, among all dead men, <%=men_violent_colp%> died violently while
only <%=wom_violent_colp%> of the women had a violent death. Here the tables:

```python, term=True
pd.crosstab(y_test, X_test["SEXO"], margins=True)
pd.crosstab(y_test, X_test["SEXO"], margins=True, normalize="index")
pd.crosstab(y_test, X_test["SEXO"], margins=True, normalize="columns")
```
Now, why sex appears to have such a low importance in the model?

The answer is most probably because a well-known issue in this way of measuring
feature importance. So far I used scikit-learn's `feature_importances_`,
that in this case correspond to an average of the importances in each tree in
the forest, which are ["computed as the (normalized) total reduction of the
criterion brought by that feature. It is also known as the Gini importance."](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).
This is also known as mean decrease in impurity.
Unfortunately, this measure has been shown to be ["affected by the number of
categories and scale of measurement of the predictor variables, which are no
direct indicators of the true importance of the variable"](https://link.springer.com/article/10.1186/1471-2105-8-25),
so variables with many categories will have artificially higher importance than
low cardinality variables. And this could well be the case here. Sex has only
three possible values (man, woman, unknown), while other features like
municipality may have over a thousand unique values.

Another issue with this method is correlated predictors. It would tend
to highlight one of the predictors with high importance, leaving the other one
with low importance (intuitively because after one predictor has been used,
the other one has only residual predictive power).

An alternative that does not have such issues is permutation importance a.k.a
mean decrease accuracy. The idea is that you randomly shuffle one predictor
at a time, and observe how much decreases the model accuracy in each tree,
and average over all the forest (hence, mean decrease accuracy).

It seems scikit-learn does not provide any function to calculate permutation
importance. But there are a number of options out there. **EDIT: July 2019,
apparently now `scikit-learn` will also provide methods to calculate
permutation importance. At least they have [merged](https://github.com/scikit-learn/scikit-learn/pull/13146/files)
that into the master repository. I haven't tried it yet, though**

`eli5` library provides permutation importance methods for scikit-learn
estimators. It's straightforward: one-liner and you get the permutation
importance. Also, it's cool you can tell the library which scoring measure
to use. In this case it would be important due to the imbalance problem we saw
earlier. The default scoring measure is accuracy and we already checked that it
could be overly optimistic. Hence, it could also be misleading in the case of
feature importance. Let's obtain feature importances based on several
scoring measures.

```python
import eli5
from eli5.sklearn import PermutationImportance

# sorted(metrics.SCORERS.keys())
with TicToc(): # TicToc just to time it
    perm1 = PermutationImportance(
        estimator=rforestclf, scoring="accuracy", n_iter=5, random_state=0
    ).fit(X_test, y_test)
with TicToc(): # TicToc just to time it
    perm2 = PermutationImportance(
        estimator=rforestclf, scoring="balanced_accuracy", n_iter=5, random_state=0
    ).fit(X_test, y_test)
with TicToc(): # TicToc just to time it
    perm3 = PermutationImportance(
        estimator=rforestclf, scoring="jaccard_weighted", n_iter=5, random_state=0
    ).fit(X_test, y_test)
with TicToc(): # TicToc just to time it
    perm4 = PermutationImportance(
        estimator=rforestclf, scoring="roc_auc", n_iter=5, random_state=0
    ).fit(X_test, y_test)
with TicToc(): # TicToc just to time it
    perm5 = PermutationImportance(
        estimator=rforestclf, scoring="recall", n_iter=5, random_state=0
    ).fit(X_test, y_test)
```

`eli5` provides a visualization method, to display a colored table.
```python, term=True
perm1_html = eli5.show_weights(perm1, feature_names = X_train.columns.tolist())
perm2_html = eli5.show_weights(perm2, feature_names = X_train.columns.tolist())
perm3_html = eli5.show_weights(perm3, feature_names = X_train.columns.tolist())
perm4_html = eli5.show_weights(perm4, feature_names = X_train.columns.tolist())
perm5_html = eli5.show_weights(perm5, feature_names = X_train.columns.tolist())
```

```python
display_markdown(perm1_html.data, raw=True)
display_markdown(perm2_html.data, raw=True)
display_markdown(perm3_html.data, raw=True)
display_markdown(perm4_html.data, raw=True)
display_markdown(perm5_html.data, raw=True)
```
